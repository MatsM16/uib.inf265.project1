{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "TRAIN_SPLIT_PERCENTAGE = 0.8\n",
    "VALIDATION_SPLIT_PERCENTAGE = 1 - TRAIN_SPLIT_PERCENTAGE\n",
    "RANDOM_SEED = 265\n",
    "EPOCH_COUNT = 30\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.ConvertImageDtype(torch.double),\n",
    "\n",
    "    # Normalize the pixel color values to be between -1 and 1\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "cifar10_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "cifar10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dataset to 'airplane' and 'bird' only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Included labels: ['airplane', 'bird']\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_LABELS = [label for label in cifar10_test.classes]\n",
    "INCLUDED_LABELS = ['airplane', 'bird']\n",
    "\n",
    "print(f\"Labels: {CIFAR10_LABELS}\")\n",
    "print(f\"Included labels: {INCLUDED_LABELS}\")\n",
    "\n",
    "included_labels_indices = [i for i, label in enumerate(CIFAR10_LABELS) if label in INCLUDED_LABELS]\n",
    "\n",
    "cifar10_train_included_indices = [i for i, target in enumerate(cifar10_train.targets) if target in included_labels_indices]\n",
    "cifar10_test_included_indices = [i for i, target in enumerate(cifar10_test.targets) if target in included_labels_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and create loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8000 entries\n",
      "Validate: 2000 entries\n",
      "Test: 2000 entries\n"
     ]
    }
   ],
   "source": [
    "train_indices = random.sample(cifar10_train_included_indices, int(TRAIN_SPLIT_PERCENTAGE * len(cifar10_train_included_indices)))\n",
    "val_indices = [i for i in cifar10_train_included_indices if i not in train_indices]\n",
    "\n",
    "train_subset = torch.utils.data.Subset(cifar10_train, train_indices)\n",
    "val_subset = torch.utils.data.Subset(cifar10_train, val_indices)\n",
    "test_subset = torch.utils.data.Subset(cifar10_test, cifar10_test_included_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train: {len(train_subset)} entries\")\n",
    "print(f\"Validate: {len(val_indices)} entries\")\n",
    "print(f\"Test: {len(cifar10_test_included_indices)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the dataset\n",
    "I will now visualize and analyse the dataset.\n",
    "\n",
    "## Obvious bises?\n",
    "To identify obvious biases in the dataset, I need to visualize the distribution of labels.  \n",
    "If one label is grosely overrepresented, I might have to downsample the other label.\n",
    "\n",
    "## What does the data look like?\n",
    "The labels sais birds and planes, but I want to know excactly what I am working with.  \n",
    "Therefore I want to show one example of each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_data_example(image_tensor):\n",
    "    # Unnormalize the pixel color values\n",
    "    image_tensor = image_tensor * 0.5 + 0.5\n",
    "\n",
    "    np_image = image_tensor.numpy()\n",
    "    np_image = np.transpose(np_image, (1, 2, 0))\n",
    "    plt.imshow(np_image)\n",
    "    plt.show()\n",
    "\n",
    "def show_data_examples(classes, loader):\n",
    "    include_labels = [x for x in classes]\n",
    "    examples = []\n",
    "    for images, labels in loader:\n",
    "        if len(include_labels) == 0: continue\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            label = classes[labels[i].item()]\n",
    "            if label not in include_labels: continue\n",
    "            examples.append(images[i])\n",
    "            include_labels.remove(label)\n",
    "\n",
    "    show_data_example(torchvision.utils.make_grid(examples))\n",
    "\n",
    "def show_label_distribution(classes, loader):\n",
    "    distribution = {label: 0 for label in classes}\n",
    "    for _, labels in loader:\n",
    "        for label in labels:\n",
    "            label_name = classes[label.item()]\n",
    "            distribution[label_name] += 1\n",
    "\n",
    "    plt.bar(distribution.keys(), distribution.values())\n",
    "    plt.show()\n",
    "\n",
    "# show_label_distribution(included_labels, train_loader)\n",
    "# show_data_examples(included_labels, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.input = nn.Linear(3 * 32 * 32, 512)\n",
    "        self.hidden1 = nn.Linear(512, 128)\n",
    "        self.hidden2 = nn.Linear(128, 32)\n",
    "        self.hidden3 = nn.Linear(32, 2)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.input(x))\n",
    "        x = self.activation(self.hidden1(x))\n",
    "        x = self.activation(self.hidden2(x))\n",
    "        x = self.hidden3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, X, y_true, loss_function):\n",
    "    # Map the labels to neurons\n",
    "    # Label 0 (airplane) -> Neuron 0\n",
    "    # Label 2 (bird) -> Neuron 1\n",
    "    y_true = torch.Tensor([[1.0, 0.0] if i.item() == 0 else [0.0, 1.0] for i in y_true])\n",
    "\n",
    "    y_pred = model(X)\n",
    "\n",
    "    return loss_function(y_pred, y_true)\n",
    "\n",
    "def train(epoch_count, optimizer, model, loss_function, train_loader):\n",
    "\n",
    "    for epoch in range(1, epoch_count + 1):\n",
    "\n",
    "        # We aggregate the loss to print after each epoch\n",
    "        # This is only for debugging purposes\n",
    "        epoch_loss = 0.0\n",
    "        epoch_size = 0\n",
    "\n",
    "        for X, y_true in train_loader:\n",
    "\n",
    "            # Reset model gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute loss and gradients\n",
    "            loss = compute_loss(model, X, y_true, loss_function)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_size += 1\n",
    "\n",
    "        # Print loss after some epochs\n",
    "        # This is for debugging purposes\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch} | Training loss: {epoch_loss / epoch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(epoch_count, model, loss_function, learning_rate, momentum, weight_decay):\n",
    "\n",
    "    momentum_buffer = [None for param in model.parameters()]\n",
    "\n",
    "    for epoch in range(1, epoch_count + 1):\n",
    "\n",
    "        # We aggregate the loss to print after each epoch\n",
    "        # This is only for debugging purposes\n",
    "        epoch_loss = 0.0\n",
    "        epoch_size = 0\n",
    "\n",
    "        for X, y_true in train_loader:\n",
    "\n",
    "            # Reset model gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Compute loss and gradients\n",
    "            loss = compute_loss(model, X, y_true, loss_function)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update weights\n",
    "            manual_sgd_step(model, learning_rate, momentum, weight_decay, momentum_buffer)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_size += 1\n",
    "\n",
    "        # Print loss after some epochs\n",
    "        # This is for debugging purposes\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch} | Training loss: {epoch_loss / epoch_size}')\n",
    "\n",
    "def manual_sgd_step(model, learning_rate, momentum, weight_decay, momentum_buffer):\n",
    "    # A single step of SGD\n",
    "    # Ref: https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
    "    # Ref: https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html#SGD\n",
    "    with torch.no_grad():\n",
    "        for i, param in enumerate(model.parameters()):\n",
    "            gradient = param.grad\n",
    "\n",
    "            # Apply L2 regularization\n",
    "            if weight_decay != 0:\n",
    "                gradient = gradient.add(param, alpha=weight_decay)\n",
    "\n",
    "            # Apply momentum\n",
    "            if momentum != 0:\n",
    "                velocity = momentum_buffer[i]\n",
    "                if velocity is None:\n",
    "                    # Initialize the velocity as the gradient, not as zero\n",
    "                    velocity = torch.clone(gradient).detach()\n",
    "                    momentum_buffer[i] = velocity\n",
    "                else:\n",
    "                    velocity.mul_(momentum).add_(gradient)\n",
    "\n",
    "                gradient = velocity\n",
    "            \n",
    "            # Update parameters\n",
    "            param.add_(gradient, alpha=-learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y_true in test_loader:\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Pick the class with the highest probability\n",
    "            value, y_pred = torch.max(y_pred.data, 1)\n",
    "            \n",
    "            # Map the predicted neurons to labels:\n",
    "            # Neuron 0 -> Label 0 (airplane)\n",
    "            # Neuron 1 = Label 2 (bird)\n",
    "            y_pred = torch.tensor([CIFAR10_LABELS.index(INCLUDED_LABELS[i.item()]) for i in y_pred])\n",
    "\n",
    "            # Update the score\n",
    "            total += y_true.size(0)\n",
    "            correct += (y_pred == y_true).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def train_and_eval(loss_function, learning_rate, momentum, weight_decay):\n",
    "    print(\"\")\n",
    "    print(\"=========================================================\")\n",
    "    print(\"Current parameters:\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Momentum: {momentum}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "\n",
    "    model_sgd = MyMLP()\n",
    "    model_manual = MyMLP()\n",
    "\n",
    "    # Copy the initial weights to the manual model\n",
    "    model_manual.load_state_dict(model_sgd.state_dict())\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"--------- Using Pytorch's SGD ---------\")\n",
    "\n",
    "    optimizer = torch.optim.SGD(model_sgd.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    train(EPOCH_COUNT, optimizer, model_sgd, loss_function, train_loader)\n",
    "\n",
    "    accuracy_sgd = compute_accuracy(model_sgd, val_loader)\n",
    "    print(\"\")\n",
    "    print(\"--- Accuracies ---\")\n",
    "    print(f\"Training accuracy: {compute_accuracy(model_sgd, train_loader)}\")\n",
    "    print(f\"Validation accuracy: {accuracy_sgd}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"--------- Using manual update ----------\")\n",
    "\n",
    "    train_manual_update(EPOCH_COUNT, model_manual, loss_function, learning_rate=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    accuracy_manual = compute_accuracy(model_manual, val_loader)\n",
    "    print(\"\")\n",
    "    print(\"--- Accuracies ---\")\n",
    "    print(f\"Training accuracy: {compute_accuracy(model_manual, train_loader)}\")\n",
    "    print(f\"Validation accuracy: {accuracy_manual}\")\n",
    "\n",
    "    # Return the best model and accuracy\n",
    "    sgd = (model_sgd, accuracy_sgd)\n",
    "    manual = (model_manual, accuracy_manual)\n",
    "    return sgd if accuracy_sgd >= accuracy_manual else manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global parameters:\n",
      "Batch size: 256\n",
      "Epoch count: 30\n",
      "Loss function: CrossEntropyLoss()\n",
      "Seed: 265\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.0\n",
      "Weight decay: 0.0\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6901844037519094\n",
      "Epoch 5 | Training loss: 0.6311858781523557\n",
      "Epoch 10 | Training loss: 0.5347327487664789\n",
      "Epoch 15 | Training loss: 0.47947322716175067\n",
      "Epoch 20 | Training loss: 0.4542207626421308\n",
      "Epoch 25 | Training loss: 0.4330152388355903\n",
      "Epoch 30 | Training loss: 0.4116433263563064\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.8345\n",
      "Validation accuracy: 0.804\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6901844037519094\n",
      "Epoch 5 | Training loss: 0.6311858781523557\n",
      "Epoch 10 | Training loss: 0.5347327487664789\n",
      "Epoch 15 | Training loss: 0.47947322716175067\n",
      "Epoch 20 | Training loss: 0.4542207626421308\n",
      "Epoch 25 | Training loss: 0.4330152388355903\n",
      "Epoch 30 | Training loss: 0.4116433263563064\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.8345\n",
      "Validation accuracy: 0.804\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.1\n",
      "Momentum: 0.0\n",
      "Weight decay: 0.0\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6395688786805538\n",
      "Epoch 5 | Training loss: 0.41059484207668373\n",
      "Epoch 10 | Training loss: 0.35709579703836286\n",
      "Epoch 15 | Training loss: 0.32763331965690606\n",
      "Epoch 20 | Training loss: 0.24383596453309883\n",
      "Epoch 25 | Training loss: 0.23630296793440492\n",
      "Epoch 30 | Training loss: 0.18264103973190285\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.89075\n",
      "Validation accuracy: 0.793\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6395688786805538\n",
      "Epoch 5 | Training loss: 0.41059484207668373\n",
      "Epoch 10 | Training loss: 0.35709579703836286\n",
      "Epoch 15 | Training loss: 0.32763331965690606\n",
      "Epoch 20 | Training loss: 0.24383596453309883\n",
      "Epoch 25 | Training loss: 0.23630296793440492\n",
      "Epoch 30 | Training loss: 0.18264103973190285\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.89075\n",
      "Validation accuracy: 0.793\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.0\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6870578056927242\n",
      "Epoch 5 | Training loss: 0.6340979512464712\n",
      "Epoch 10 | Training loss: 0.5731521950125099\n",
      "Epoch 15 | Training loss: 0.5340724982569348\n",
      "Epoch 20 | Training loss: 0.507455685840503\n",
      "Epoch 25 | Training loss: 0.4842918040760253\n",
      "Epoch 30 | Training loss: 0.4629269077648901\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.820125\n",
      "Validation accuracy: 0.7925\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6870578056927242\n",
      "Epoch 5 | Training loss: 0.6340979512464712\n",
      "Epoch 10 | Training loss: 0.5731521950125099\n",
      "Epoch 15 | Training loss: 0.5340724982569348\n",
      "Epoch 20 | Training loss: 0.507455685840503\n",
      "Epoch 25 | Training loss: 0.4842918040760253\n",
      "Epoch 30 | Training loss: 0.4629269077648901\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.820125\n",
      "Validation accuracy: 0.7925\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.0\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6666271222733655\n",
      "Epoch 5 | Training loss: 0.41264651410952263\n",
      "Epoch 10 | Training loss: 0.2800718913960244\n",
      "Epoch 15 | Training loss: 0.2139815154548847\n",
      "Epoch 20 | Training loss: 0.16704098300513948\n",
      "Epoch 25 | Training loss: 0.11599786485557972\n",
      "Epoch 30 | Training loss: 0.10636336206057874\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.93875\n",
      "Validation accuracy: 0.836\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6666271222733655\n",
      "Epoch 5 | Training loss: 0.41264651410952263\n",
      "Epoch 10 | Training loss: 0.2800718913960244\n",
      "Epoch 15 | Training loss: 0.2139815154548847\n",
      "Epoch 20 | Training loss: 0.16704098300513948\n",
      "Epoch 25 | Training loss: 0.11599786485557972\n",
      "Epoch 30 | Training loss: 0.10636336206057874\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.93875\n",
      "Validation accuracy: 0.836\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.67911034829112\n",
      "Epoch 5 | Training loss: 0.43785978323091335\n",
      "Epoch 10 | Training loss: 0.3266962147212774\n",
      "Epoch 15 | Training loss: 0.22941623455351084\n",
      "Epoch 20 | Training loss: 0.23651853228485128\n",
      "Epoch 25 | Training loss: 0.10767309773684866\n",
      "Epoch 30 | Training loss: 0.17205526266287627\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.938625\n",
      "Validation accuracy: 0.8385\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.67911034829112\n",
      "Epoch 5 | Training loss: 0.43785978323091335\n",
      "Epoch 10 | Training loss: 0.3266962147212774\n",
      "Epoch 15 | Training loss: 0.22941623455351084\n",
      "Epoch 20 | Training loss: 0.23651853228485128\n",
      "Epoch 25 | Training loss: 0.10767309773684866\n",
      "Epoch 30 | Training loss: 0.17205526266287627\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.938625\n",
      "Validation accuracy: 0.8385\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.001\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6784321957980282\n",
      "Epoch 5 | Training loss: 0.4212055394903632\n",
      "Epoch 10 | Training loss: 0.2918211692586134\n",
      "Epoch 15 | Training loss: 0.17990649059329397\n",
      "Epoch 20 | Training loss: 0.19027272808468546\n",
      "Epoch 25 | Training loss: 0.15054778585451192\n",
      "Epoch 30 | Training loss: 0.10794558701619723\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.942875\n",
      "Validation accuracy: 0.845\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6784321957980282\n",
      "Epoch 5 | Training loss: 0.4212055394903632\n",
      "Epoch 10 | Training loss: 0.2918211692586134\n",
      "Epoch 15 | Training loss: 0.17990649059329397\n",
      "Epoch 20 | Training loss: 0.19027272808468546\n",
      "Epoch 25 | Training loss: 0.15054778585451192\n",
      "Epoch 30 | Training loss: 0.10794558701619723\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.942875\n",
      "Validation accuracy: 0.845\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.8\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6820539182610499\n",
      "Epoch 5 | Training loss: 0.47242102371972444\n",
      "Epoch 10 | Training loss: 0.3934139803023009\n",
      "Epoch 15 | Training loss: 0.32798522928591317\n",
      "Epoch 20 | Training loss: 0.26226635121094977\n",
      "Epoch 25 | Training loss: 0.2028177213002897\n",
      "Epoch 30 | Training loss: 0.13864736934536842\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.95875\n",
      "Validation accuracy: 0.837\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6820539182610499\n",
      "Epoch 5 | Training loss: 0.47242102371972444\n",
      "Epoch 10 | Training loss: 0.3934139803023009\n",
      "Epoch 15 | Training loss: 0.32798522928591317\n",
      "Epoch 20 | Training loss: 0.26226635121094977\n",
      "Epoch 25 | Training loss: 0.2028177213002897\n",
      "Epoch 30 | Training loss: 0.13864736934536842\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.95875\n",
      "Validation accuracy: 0.837\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.1\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.5611051684301194\n",
      "Epoch 5 | Training loss: 0.38168787911096536\n",
      "Epoch 10 | Training loss: 0.3728301183859261\n",
      "Epoch 15 | Training loss: 0.35718658596793085\n",
      "Epoch 20 | Training loss: 0.341921986877993\n",
      "Epoch 25 | Training loss: 0.3634073990871488\n",
      "Epoch 30 | Training loss: 0.3167488891061028\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.87\n",
      "Validation accuracy: 0.8055\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.5611051684301194\n",
      "Epoch 5 | Training loss: 0.38168787911096536\n",
      "Epoch 10 | Training loss: 0.3728301183859261\n",
      "Epoch 15 | Training loss: 0.35718658596793085\n",
      "Epoch 20 | Training loss: 0.341921986877993\n",
      "Epoch 25 | Training loss: 0.3634073990871488\n",
      "Epoch 30 | Training loss: 0.3167488891061028\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.87\n",
      "Validation accuracy: 0.8055\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.1\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.001\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.5610747776458896\n",
      "Epoch 5 | Training loss: 0.32006377200573966\n",
      "Epoch 10 | Training loss: 0.22457644842529642\n",
      "Epoch 15 | Training loss: 0.180049652450751\n",
      "Epoch 20 | Training loss: 0.2169835163308006\n",
      "Epoch 25 | Training loss: 0.12201715193733936\n",
      "Epoch 30 | Training loss: 0.1038814099031469\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.937375\n",
      "Validation accuracy: 0.82\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.5610747776458896\n",
      "Epoch 5 | Training loss: 0.32006377200573966\n",
      "Epoch 10 | Training loss: 0.22457644842529642\n",
      "Epoch 15 | Training loss: 0.180049652450751\n",
      "Epoch 20 | Training loss: 0.2169835163308006\n",
      "Epoch 25 | Training loss: 0.12201715193733936\n",
      "Epoch 30 | Training loss: 0.1038814099031469\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.937375\n",
      "Validation accuracy: 0.82\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.1\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.5594840443324514\n",
      "Epoch 5 | Training loss: 0.3672863545555278\n",
      "Epoch 10 | Training loss: 0.3606588815135386\n",
      "Epoch 15 | Training loss: 0.3895673443514497\n",
      "Epoch 20 | Training loss: 0.35162334904567555\n",
      "Epoch 25 | Training loss: 0.3322391030281797\n",
      "Epoch 30 | Training loss: 0.3076611949873022\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.87425\n",
      "Validation accuracy: 0.815\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.5594840443324514\n",
      "Epoch 5 | Training loss: 0.3672863545555278\n",
      "Epoch 10 | Training loss: 0.3606588815135386\n",
      "Epoch 15 | Training loss: 0.3895673443514497\n",
      "Epoch 20 | Training loss: 0.35162334904567555\n",
      "Epoch 25 | Training loss: 0.3322391030281797\n",
      "Epoch 30 | Training loss: 0.3076611949873022\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.87425\n",
      "Validation accuracy: 0.815\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.9\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 11.48756237417679\n",
      "Epoch 5 | Training loss: nan\n",
      "Epoch 10 | Training loss: nan\n",
      "Epoch 15 | Training loss: nan\n",
      "Epoch 20 | Training loss: nan\n",
      "Epoch 25 | Training loss: nan\n",
      "Epoch 30 | Training loss: nan\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.498375\n",
      "Validation accuracy: 0.5065\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 11.48756237417679\n",
      "Epoch 5 | Training loss: nan\n",
      "Epoch 10 | Training loss: nan\n",
      "Epoch 15 | Training loss: nan\n",
      "Epoch 20 | Training loss: nan\n",
      "Epoch 25 | Training loss: nan\n",
      "Epoch 30 | Training loss: nan\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy: 0.498375\n",
      "Validation accuracy: 0.5065\n",
      "\n",
      "=========================================================\n",
      "Best parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.001\n",
      "Test accuracy: 0.8465\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters = [\n",
    "    {'learning_rate': .01, 'momentum': .0, 'weight_decay': .000},\n",
    "    {'learning_rate': .10, 'momentum': .0, 'weight_decay': .000},\n",
    "    {'learning_rate': .01, 'momentum': .0, 'weight_decay': .010},\n",
    "    {'learning_rate': .01, 'momentum': .9, 'weight_decay': .000},\n",
    "    {'learning_rate': .01, 'momentum': .9, 'weight_decay': .010},\n",
    "    {'learning_rate': .01, 'momentum': .9, 'weight_decay': .001},\n",
    "    {'learning_rate': .01, 'momentum': .8, 'weight_decay': .010},\n",
    "    {'learning_rate': .10, 'momentum': .9, 'weight_decay': .010},\n",
    "    {'learning_rate': .10, 'momentum': .9, 'weight_decay': .001},\n",
    "    {'learning_rate': .10, 'momentum': .9, 'weight_decay': .010},\n",
    "    {'learning_rate': .90, 'momentum': .9, 'weight_decay': .010},\n",
    "]\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Global parameters:\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epoch count: {EPOCH_COUNT}\")\n",
    "print(f\"Loss function: {loss_function}\")\n",
    "print(f\"Seed: {RANDOM_SEED}\")\n",
    "\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "for params in hyper_parameters:\n",
    "    model, accuracy = train_and_eval(loss_function, params['learning_rate'], params['momentum'], params['weight_decay'])\n",
    "\n",
    "    # Keep track of the best model on the validation set\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "\n",
    "print(\"\")\n",
    "print(\"=========================================================\")\n",
    "print(\"Best parameters:\")\n",
    "print(f\"Learning rate: {best_params['learning_rate']}\")\n",
    "print(f\"Momentum: {best_params['momentum']}\")\n",
    "print(f\"Weight decay: {best_params['weight_decay']}\")\n",
    "\n",
    "# Show accuracy on unseen test data\n",
    "test_accuracy = compute_accuracy(best_model, test_loader)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
