{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "TRAIN_SPLIT_PERCENTAGE = 0.8\n",
    "VALIDATION_SPLIT_PERCENTAGE = 1 - TRAIN_SPLIT_PERCENTAGE\n",
    "RANDOM_SEED = 265\n",
    "EPOCH_COUNT = 1\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.ConvertImageDtype(torch.double),\n",
    "\n",
    "    # Normalize the pixel color values to be between -1 and 1\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "cifar10_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "cifar10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dataset to 'airplane' and 'bird' only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Included labels: ['airplane', 'bird']\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_LABELS = [label for label in cifar10_test.classes]\n",
    "INCLUDED_LABELS = ['airplane', 'bird']\n",
    "\n",
    "print(f\"Labels: {CIFAR10_LABELS}\")\n",
    "print(f\"Included labels: {INCLUDED_LABELS}\")\n",
    "\n",
    "included_labels_indices = [i for i, label in enumerate(CIFAR10_LABELS) if label in INCLUDED_LABELS]\n",
    "\n",
    "cifar10_train_included_indices = [i for i, target in enumerate(cifar10_train.targets) if target in included_labels_indices]\n",
    "cifar10_test_included_indices = [i for i, target in enumerate(cifar10_test.targets) if target in included_labels_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and create loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8000 entries\n",
      "Validate: 2000 entries\n",
      "Test: 2000 entries\n"
     ]
    }
   ],
   "source": [
    "train_indices = random.sample(cifar10_train_included_indices, int(TRAIN_SPLIT_PERCENTAGE * len(cifar10_train_included_indices)))\n",
    "val_indices = [i for i in cifar10_train_included_indices if i not in train_indices]\n",
    "\n",
    "train_subset = torch.utils.data.Subset(cifar10_train, train_indices)\n",
    "val_subset = torch.utils.data.Subset(cifar10_train, val_indices)\n",
    "test_subset = torch.utils.data.Subset(cifar10_test, cifar10_test_included_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train: {len(train_subset)} entries\")\n",
    "print(f\"Validate: {len(val_indices)} entries\")\n",
    "print(f\"Test: {len(cifar10_test_included_indices)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the dataset\n",
    "I will now visualize and analyse the dataset.\n",
    "\n",
    "## Obvious bises?\n",
    "To identify obvious biases in the dataset, I need to visualize the distribution of labels.  \n",
    "If one label is grosely overrepresented, I might have to downsample the other label.\n",
    "\n",
    "## What does the data look like?\n",
    "The labels sais birds and planes, but I want to know excactly what I am working with.  \n",
    "Therefore I want to show one example of each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_data_example(image_tensor):\n",
    "    # Unnormalize the pixel color values\n",
    "    image_tensor = image_tensor * 0.5 + 0.5\n",
    "\n",
    "    np_image = image_tensor.numpy()\n",
    "    np_image = np.transpose(np_image, (1, 2, 0))\n",
    "    plt.imshow(np_image)\n",
    "    plt.show()\n",
    "\n",
    "def show_data_examples(classes, loader):\n",
    "    include_labels = [x for x in classes]\n",
    "    examples = []\n",
    "    for images, labels in loader:\n",
    "        if len(include_labels) == 0: continue\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            label = classes[labels[i].item()]\n",
    "            if label not in include_labels: continue\n",
    "            examples.append(images[i])\n",
    "            include_labels.remove(label)\n",
    "\n",
    "    show_data_example(torchvision.utils.make_grid(examples))\n",
    "\n",
    "def show_label_distribution(classes, loader):\n",
    "    distribution = {label: 0 for label in classes}\n",
    "    for _, labels in loader:\n",
    "        for label in labels:\n",
    "            label_name = classes[label.item()]\n",
    "            distribution[label_name] += 1\n",
    "\n",
    "    plt.bar(distribution.keys(), distribution.values())\n",
    "    plt.show()\n",
    "\n",
    "# show_label_distribution(included_labels, train_loader)\n",
    "# show_data_examples(included_labels, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.input = nn.Linear(3 * 32 * 32, 512)\n",
    "        self.hidden1 = nn.Linear(512, 128)\n",
    "        self.hidden2 = nn.Linear(128, 32)\n",
    "        self.hidden3 = nn.Linear(32, 2)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.input(x))\n",
    "        x = self.activation(self.hidden1(x))\n",
    "        x = self.activation(self.hidden2(x))\n",
    "        x = self.hidden3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, X, y_true, loss_function):\n",
    "    # Map the labels to neurons\n",
    "    # Label 0 (airplane) -> Neuron 0\n",
    "    # Label 2 (bird) -> Neuron 1\n",
    "    y_true = torch.Tensor([[1.0, 0.0] if i.item() == 0 else [0.0, 1.0] for i in y_true])\n",
    "\n",
    "    y_pred = model(X)\n",
    "\n",
    "    return loss_function(y_pred, y_true)\n",
    "\n",
    "def train(epoch_count, optimizer, model, loss_function, train_loader):\n",
    "\n",
    "    for epoch in range(1, epoch_count + 1):\n",
    "\n",
    "        # We aggregate the loss to print after each epoch\n",
    "        # This is only for debugging purposes\n",
    "        epoch_loss = 0.0\n",
    "        epoch_size = 0\n",
    "\n",
    "        for X, y_true in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = compute_loss(model, X, y_true, loss_function)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_size += 1\n",
    "\n",
    "        # Print loss after some epochs\n",
    "        # This is for debugging purposes\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch} | Training loss: {epoch_loss / epoch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(epoch_count, model, loss_function, leanring_rate, momentum, weight_decay):\n",
    "\n",
    "    # Keep track of accumulated velocities caused by the momentum\n",
    "    gradient_velocities = [torch.zeros_like(param) for param in model.parameters()]\n",
    "\n",
    "    for epoch in range(1, epoch_count + 1):\n",
    "\n",
    "        # We aggregate the loss to print after each epoch\n",
    "        # This is only for debugging purposes\n",
    "        epoch_loss = 0.0\n",
    "        epoch_size = 0\n",
    "\n",
    "        for X, y_true in train_loader:\n",
    "\n",
    "            loss = compute_loss(model, X, y_true, loss_function)\n",
    "\n",
    "            # Reset model gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for param, velocity in zip(model.parameters(), gradient_velocities):\n",
    "\n",
    "                    # Update velocity\n",
    "                    velocity *= momentum\n",
    "                    velocity += param.grad\n",
    "                    param -= leanring_rate * velocity\n",
    "\n",
    "                    # L2 Regularization through weight decay\n",
    "                    param *= 1 - weight_decay * leanring_rate\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_size += 1\n",
    "\n",
    "        # Print loss after some epochs\n",
    "        # This is for debugging purposes\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch} | Training loss: {epoch_loss / epoch_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (4047054521.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[60], line 58\u001b[1;36m\u001b[0m\n\u001b[1;33m    return (model_sgd, accuracy_sgd) if accuracy_sgd >= accuracy_manual\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y_true in test_loader:\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Pick the class with the highest probability\n",
    "            value, y_pred = torch.max(y_pred.data, 1)\n",
    "            \n",
    "            # Map the predicted neurons to labels:\n",
    "            # Neuron 0 -> Label 0 (airplane)\n",
    "            # Neuron 1 = Label 2 (bird)\n",
    "            y_pred = torch.tensor([CIFAR10_LABELS.index(INCLUDED_LABELS[i.item()]) for i in y_pred])\n",
    "\n",
    "            # Update the score\n",
    "            total += y_true.size(0)\n",
    "            correct += (y_pred == y_true).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def train_and_eval(loss_function, learning_rate, momentum, weight_decay):\n",
    "    print(\"\")\n",
    "    print(\"=========================================================\")\n",
    "    print(\"Current parameters:\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Momentum: {momentum}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"--------- Using Pytorch's SGD ---------\")\n",
    "    model_sgd = MyMLP()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model_sgd.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    train(EPOCH_COUNT, optimizer, model_sgd, loss_function, train_loader)\n",
    "\n",
    "    accuracy_sgd = compute_accuracy(model_sgd, val_loader)\n",
    "    print(\"\")\n",
    "    print(\"--- Accuracies ---\")\n",
    "    print(f\"Training accuracy: {compute_accuracy(model_sgd, train_loader)}\")\n",
    "    print(f\"Validation accuracy: {accuracy_sgd}\")\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"--------- Using manual update ----------\")\n",
    "    model_manual = MyMLP()\n",
    "\n",
    "    # Train somehow\n",
    "    train_manual_update(EPOCH_COUNT, model_manual, loss_function, leanring_rate=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    accuracy_manual = compute_accuracy(model_manual, val_loader)\n",
    "    print(\"\")\n",
    "    print(\"--- Accuracies ---\")\n",
    "    print(f\"Training accuracy: {compute_accuracy(model_manual, train_loader)}\")\n",
    "    print(f\"Validation accuracy: {accuracy_manual}\")\n",
    "\n",
    "    # Return the best model and accuracy\n",
    "    sgd = (model_sgd, accuracy_sgd)\n",
    "    manual = (model_manual, accuracy_manual)\n",
    "    return sgd if accuracy_sgd >= accuracy_manual else manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global parameters:\n",
      "Batch size:  256\n",
      "Epoch count:  1\n",
      "Loss function:  CrossEntropyLoss()\n",
      "Seed:  265\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.0\n",
      "Weight decay: 0.0\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6901844037519094\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.498375\n",
      "Validation accuracy:  0.5065\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6895472081309372\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.498375\n",
      "Validation accuracy:  0.5065\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.0\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6999775389983581\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.498375\n",
      "Validation accuracy:  0.5065\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6891115593474749\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.498375\n",
      "Validation accuracy:  0.5065\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.0\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6685836668868892\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.717875\n",
      "Validation accuracy:  0.6975\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6656229385438077\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.72375\n",
      "Validation accuracy:  0.704\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6532999799631907\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.73125\n",
      "Validation accuracy:  0.7075\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6586682613486425\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.727125\n",
      "Validation accuracy:  0.708\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.001\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6698869621781487\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.7215\n",
      "Validation accuracy:  0.699\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.6685592475054583\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.721875\n",
      "Validation accuracy:  0.702\n",
      "\n",
      "=========================================================\n",
      "Current parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.8\n",
      "Weight decay: 0.01\n",
      "\n",
      "--------- Using Pytorch's SGD ---------\n",
      "Epoch 1 | Training loss: 0.6662014648010675\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.718625\n",
      "Validation accuracy:  0.698\n",
      "\n",
      "--------- Using manual update ----------\n",
      "Epoch 1 | Training loss: 0.679683692459391\n",
      "\n",
      "--- Accuracies ---\n",
      "Training accuracy:  0.680875\n",
      "Validation accuracy:  0.665\n",
      "=========================================================\n",
      "Best parameters:\n",
      "Learning rate: 0.01\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.01\n",
      "Test accuracy:  0.731\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters = [\n",
    "    {'learning_rate': .01, 'momentum': .0, 'weight_decay': .000},\n",
    "    {'learning_rate': .01, 'momentum': .0, 'weight_decay': .010},\n",
    "    {'learning_rate': .01, 'momentum': .9, 'weight_decay': .000},\n",
    "    {'learning_rate': .01, 'momentum': .9, 'weight_decay': .010},\n",
    "    {'learning_rate': .01, 'momentum': .9, 'weight_decay': .001},\n",
    "    {'learning_rate': .01, 'momentum': .8, 'weight_decay': .010},\n",
    "]\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Global parameters:\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epoch count: {EPOCH_COUNT}\")\n",
    "print(f\"Loss function: {loss_function}\")\n",
    "print(f\"Seed: {RANDOM_SEED}\")\n",
    "\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "for params in hyper_parameters:\n",
    "    model, accuracy = train_and_eval(loss_function, params['learning_rate'], params['momentum'], params['weight_decay'])\n",
    "\n",
    "    # Keep track of the best model on the validation set\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "\n",
    "print(\"\")\n",
    "print(\"=========================================================\")\n",
    "print(\"Best parameters:\")\n",
    "print(f\"Learning rate: {best_params['learning_rate']}\")\n",
    "print(f\"Momentum: {best_params['momentum']}\")\n",
    "print(f\"Weight decay: {best_params['weight_decay']}\")\n",
    "\n",
    "# Show accuracy on unseen test data\n",
    "test_accuracy = compute_accuracy(best_model, test_loader)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
